{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transliterate\n",
      "  Using cached transliterate-1.10.2-py2.py3-none-any.whl (45 kB)\n",
      "Requirement already satisfied: six>=1.1.0 in c:\\users\\vital\\anaconda3\\lib\\site-packages (from transliterate) (1.14.0)\n",
      "Installing collected packages: transliterate\n",
      "Successfully installed transliterate-1.10.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transliterate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymorphy2\n",
      "  Using cached pymorphy2-0.8-py2.py3-none-any.whl (46 kB)\n",
      "Processing c:\\users\\vital\\appdata\\local\\pip\\cache\\wheels\\9b\\04\\dd\\7daf4150b6d9b12949298737de9431a324d4b797ffd63f526e\\docopt-0.6.2-py2.py3-none-any.whl\n",
      "Collecting pymorphy2-dicts<3.0,>=2.4\n",
      "  Using cached pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1 MB)\n",
      "Collecting dawg-python>=0.7\n",
      "  Using cached DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: docopt, pymorphy2-dicts, dawg-python, pymorphy2\n",
      "Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985\n"
     ]
    }
   ],
   "source": [
    "!pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transliterate\n",
    "from transliterate import translit, get_available_language_codes\n",
    "import pymorphy2\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Т."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Скачивание файлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = []\n",
    "for i in os.walk('childes_Tosia'):\n",
    "    folder.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводим список всех файлов и папок "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = []\n",
    "for address, dirs, files in folder:\n",
    "    for file in files:\n",
    "        filenames.append(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводим список всех файлов, содержащих диалоги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []  # список готовых директорий к файлам с диалогами\n",
    "for filename in filenames:\n",
    "    if filename.startswith('TD'):\n",
    "        directory = 'childes_Tosia/malenkaya/'\n",
    "    else:\n",
    "        directory = 'childes_Tosia/'\n",
    "    path = directory + filename\n",
    "    paths.append(path)\n",
    "    #print(path)\n",
    "\n",
    "#print(len(paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разделение реплик на то, что ребенок слышит, и то, что он говорит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "dict_words = []\n",
    "\n",
    "textChild = ''\n",
    "textParents = ''\n",
    "\n",
    "for filename in paths:\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        file = f.readlines()\n",
    "        for line in file:\n",
    "            line = translit(line, 'ru')\n",
    "            line = re.sub('йо', 'ё', line)\n",
    "            line = re.sub('шч', 'щ', line)\n",
    "            if line.startswith('*ЦХИ'):  # выбираем только реплики ребенка \n",
    "                line = re.sub('\"*\".*', '', line)\n",
    "                line = re.sub('[0-9_]', '', line)\n",
    "                textChild += line.lower()\n",
    "            elif line.startswith('*'):\n",
    "                line = re.sub('\"*\".*', '', line)\n",
    "                line = re.sub('[0-9_]', '', line)\n",
    "                textParents += line.lower()\n",
    "        \n",
    "with open('TosiaSays.txt', 'w+', encoding='utf-8') as f:\n",
    "    f.write(textChild)\n",
    "with open('TosiaHears.txt', 'w+', encoding='utf-8') as f:\n",
    "    f.write(textParents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WordsCounting(filepath):\n",
    "    with open(filepath, 'r+', encoding='utf-8') as f:\n",
    "        text = f.readlines()\n",
    "        # список из всех слов, которые говорит или слышит ребенок\n",
    "        words = []\n",
    "        for line in text:\n",
    "            if ' [: ' in line:\n",
    "                line = line.replace(' [:', 'ERR')\n",
    "            for word in line.lower().translate(str.maketrans(dict.fromkeys(string.punctuation))).split():\n",
    "                if not word.endswith('err'):\n",
    "                    words.append(word)\n",
    "\n",
    "    # список из словарей вида слово:часть речи\n",
    "    dict_words = [] \n",
    "    for word in words:\n",
    "        pos = morph.parse(word)[0].tag.POS\n",
    "        d = {}\n",
    "        d[word] = pos\n",
    "        dict_words.append(d)\n",
    "\n",
    "    pos = []   \n",
    "    \n",
    "    # топ-10 слов и топ-10 существительных, которые слышит или говорит ребенок\n",
    "    all_words = []\n",
    "    all_nouns = []\n",
    "    forbidden = ['цхи', 'ххх', 'мот', 'фат', 'æто',\n",
    "                 'лаугхинга', 'чико', 'нана', 'мотхер', 'бро',\n",
    "                 'мота', 'xxx', 'сис', '\\x15\\x15', 'ала',\n",
    "                'деу', 'клякляу', 'цхилд', 'нанна', 'сцреаминг']\n",
    "    for d in dict_words:\n",
    "        for key, value in d.items():\n",
    "            key = morph.parse(key)[0].normal_form\n",
    "            if key not in forbidden:\n",
    "                all_words.append(key)\n",
    "                if value != None:\n",
    "                    pos.append(value)\n",
    "            if value == 'NOUN' and key not in forbidden:\n",
    "                all_nouns.append(key)\n",
    "\n",
    "    # топ частей речи, которые слышит или говорит ребенок\n",
    "    top_pos = Counter(pos)\n",
    "    print('Распределение по частям речи ', top_pos)\n",
    "                \n",
    "    # общая размерность корпуса вместе со словами, у которых тэг части речи None\n",
    "    print('Всего слов в этой части корпуса (вместе с неопределенной частью речи)', len(all_words))\n",
    "    print('Всего слов в этой части корпуса (часть речи определена)', len(pos))\n",
    "                \n",
    "    sw = stopwords.words('russian')\n",
    "    \n",
    "    filtered_words = [w for w in all_words if w not in sw]\n",
    "    filtered_nouns = [w for w in all_nouns if w not in sw]\n",
    "    \n",
    "    top_words = Counter(filtered_words)\n",
    "    top_words = dict(top_words)\n",
    "    top_words = {c: top_words[c] for c in top_words if top_words[c] > 2 and len(c) > 2}\n",
    "    top_words = (sorted(top_words.items(), key=lambda x: x[1], reverse=True))[:10]\n",
    "    \n",
    "    top_nouns = Counter(filtered_nouns)\n",
    "    top_nouns = dict(top_nouns)\n",
    "    top_nouns = {c: top_nouns[c] for c in top_nouns if top_nouns[c] > 2 and len(c) > 2}\n",
    "    top_nouns = (sorted(top_nouns.items(), key=lambda x: x[1], reverse=True))[:11]\n",
    "    \n",
    "    print('Топ-10 всех слов', top_words)\n",
    "    print('Топ-10 всех существительных', top_nouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Что Т. говорит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Распределение по частям речи  Counter({'NOUN': 2319, 'NPRO': 1327, 'VERB': 1259, 'PRCL': 1234, 'ADVB': 613, 'CONJ': 559, 'ADJF': 475, 'PRED': 464, 'INTJ': 343, 'PREP': 294, 'INFN': 209, 'NUMR': 75, 'ADJS': 56, 'GRND': 40, 'COMP': 27, 'PRTS': 7})\n",
      "Всего слов в этой части корпуса (вместе с неопределенной частью речи) 10135\n",
      "Всего слов в этой части корпуса (часть речи определена) 9301\n",
      "Топ-10 всех слов [('xочить', 102), ('няня', 100), ('ещё', 88), ('ама', 83), ('смотреть', 77), ('видеть', 76), ('мочь', 62), ('большой', 62), ('варя', 54), ('тося', 52)]\n",
      "Топ-10 всех существительных [('няня', 100), ('ама', 83), ('варя', 54), ('тося', 52), ('мама', 36), ('стасик', 33), ('метр', 25), ('папа', 24), ('кошка', 19), ('ёлочка', 19), ('ромашка', 18)]\n"
     ]
    }
   ],
   "source": [
    "WordsCounting('TosiaSays.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Что Т. слышит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Распределение по частям речи  Counter({'NOUN': 7022, 'VERB': 4495, 'CONJ': 3016, 'NPRO': 2884, 'PRCL': 2788, 'ADVB': 2129, 'PREP': 1725, 'ADJF': 1640, 'INFN': 902, 'INTJ': 662, 'PRED': 431, 'ADJS': 405, 'GRND': 218, 'NUMR': 168, 'COMP': 93, 'PRTS': 39, 'PRTF': 18})\n",
      "Всего слов в этой части корпуса (вместе с неопределенной частью речи) 29665\n",
      "Всего слов в этой части корпуса (часть речи определена) 28635\n",
      "Топ-10 всех слов [('тося', 454), ('давать', 301), ('ещё', 173), ('смотреть', 163), ('мочь', 139), ('сказать', 135), ('весь', 135), ('тосй', 109), ('пойти', 108), ('дать', 105)]\n",
      "Топ-10 всех существительных [('тося', 454), ('тосй', 109), ('мама', 102), ('тоня', 63), ('варя', 62), ('свет', 59), ('молодец', 54), ('ромашка', 48), ('девочка', 42), ('нога', 41), ('ножка', 40)]\n"
     ]
    }
   ],
   "source": [
    "WordsCounting('TosiaHears.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Я."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Скачивание файлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = []\n",
    "for i in os.walk('childes_Yasha'):\n",
    "    folder.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводим список всех файлов и папок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = []\n",
    "for address, dirs, files in folder:\n",
    "    for file in files:\n",
    "        filenames.append(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводим список всех файлов, содержащих диалоги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10.txt', '11.txt', '12.txt', '13.06.2018.txt', '13.txt', '13_02_2018.txt', '14.txt', '15.txt', '16.txt', '18.txt', '19.txt', '20.txt', '21.cha', '22.cha', '22_02_2018.cha', '23.cha', '24.cha', '24_03_2018.cha', '25.cha', '26.cha', '27.01.2018.cha', '27.cha', '6_02_2018.txt', '7.txt', '8.txt']\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "new = []\n",
    "for filename in filenames:\n",
    "    if filename[0].isnumeric():\n",
    "        new.append(filename)\n",
    "print(new)\n",
    "print(len(new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []  # список готовых директорий к файлам с диалогами\n",
    "for filename in new:\n",
    "    directory = 'childes_Yasha/'\n",
    "    path = directory + filename\n",
    "    paths.append(path)\n",
    "    #print(path)\n",
    "\n",
    "#print(len(paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разделение реплик на то, что ребенок слышит, и то, что он говорит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "dict_words = []\n",
    "\n",
    "textChild = ''\n",
    "textParents = ''\n",
    "\n",
    "for filename in paths:\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        file = f.readlines()\n",
    "        for line in file:\n",
    "            line = translit(line, 'ru')\n",
    "            line = re.sub('йо', 'ё', line)\n",
    "            line = re.sub('шч', 'щ', line)\n",
    "            if line.startswith('*ЦХИ'):  # выбираем только реплики ребенка \n",
    "                line = re.sub('\"*\".*', '', line)\n",
    "                line = re.sub('[0-9_]', '', line)\n",
    "                textChild += line.lower()\n",
    "            elif line.startswith('*'):\n",
    "                line = re.sub('\"*\".*', '', line)\n",
    "                line = re.sub('[0-9_]', '', line)\n",
    "                textParents += line.lower()\n",
    "        \n",
    "with open('YashaSays.txt', 'w+', encoding='utf-8') as f:\n",
    "    f.write(textChild)\n",
    "with open('YashaHears.txt', 'w+', encoding='utf-8') as f:\n",
    "    f.write(textParents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Что Я. говорит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Распределение по частям речи  Counter({'NOUN': 3996, 'PRCL': 1876, 'VERB': 1438, 'INTJ': 966, 'ADVB': 911, 'CONJ': 827, 'ADJF': 714, 'PREP': 658, 'NPRO': 486, 'PRED': 434, 'NUMR': 171, 'INFN': 157, 'ADJS': 87, 'GRND': 82, 'PRTS': 59, 'COMP': 11, 'PRTF': 1})\n",
      "Всего слов в этой части корпуса (вместе с неопределенной частью речи) 14363\n",
      "Всего слов в этой части корпуса (часть речи определена) 12874\n",
      "Топ-10 всех слов [('упасть', 147), ('знать', 104), ('папа', 103), ('дом', 97), ('миша', 94), ('ещё', 94), ('мама', 88), ('дать', 78), ('весь', 74), ('есхчё', 74)]\n",
      "Топ-10 всех существительных [('папа', 103), ('дом', 97), ('миша', 94), ('мама', 88), ('есхчё', 74), ('метр', 71), ('мяч', 67), ('собака', 65), ('поезд', 54), ('яша', 47), ('кубик', 46)]\n"
     ]
    }
   ],
   "source": [
    "WordsCounting('YashaSays.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Что Я. слышит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Распределение по частям речи  Counter({'NOUN': 4799, 'VERB': 3598, 'CONJ': 3335, 'PRCL': 2371, 'ADVB': 2286, 'NPRO': 1998, 'ADJF': 1131, 'PREP': 964, 'INFN': 576, 'INTJ': 512, 'PRED': 500, 'ADJS': 206, 'NUMR': 165, 'GRND': 122, 'COMP': 82, 'PRTS': 60, 'PRTF': 5})\n",
      "Всего слов в этой части корпуса (вместе с неопределенной частью речи) 23388\n",
      "Всего слов в этой части корпуса (часть речи определена) 22710\n",
      "Топ-10 всех слов [('яша', 544), ('давать', 299), ('ещё', 250), ('весь', 145), ('показать', 144), ('буква', 137), ('пожалуйста', 109), ('делать', 109), ('смотреть', 109), ('мочь', 103)]\n",
      "Топ-10 всех существительных [('яша', 544), ('буква', 137), ('миша', 102), ('поезд', 84), ('дом', 75), ('мама', 70), ('книжка', 66), ('малыш', 51), ('машинка', 51), ('собака', 51)]\n"
     ]
    }
   ],
   "source": [
    "WordsCounting('YashaHears.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
