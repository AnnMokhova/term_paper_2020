{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transliterate import translit, get_available_language_codes\n",
    "import pymorphy2\n",
    "import os\n",
    "import re\n",
    "import transliterate\n",
    "import string\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тося"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Скачивание файлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = []\n",
    "for i in os.walk('childes_Tosia'):\n",
    "    folder.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводим список всех файлов и папок "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = []\n",
    "for address, dirs, files in folder:\n",
    "    for file in files:\n",
    "        filenames.append(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводим список всех файлов, содержащих диалоги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []  # список готовых директорий к файлам с диалогами\n",
    "for filename in filenames:\n",
    "    if filename.startswith('TD'):\n",
    "        directory = 'childes_Tosia/malenkaya/'\n",
    "    else:\n",
    "        directory = 'childes_Tosia/'\n",
    "    path = directory + filename\n",
    "    paths.append(path)\n",
    "    #print(path)\n",
    "\n",
    "#print(len(paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разделение реплик на то, что ребенок слышит, и то, что он говорит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "dict_words = []\n",
    "\n",
    "textChild = ''\n",
    "textParents = ''\n",
    "\n",
    "for filename in paths:\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        file = f.readlines()\n",
    "        for line in file:\n",
    "            line = translit(line, 'ru')\n",
    "            line = re.sub('йо', 'ё', line)\n",
    "            if line.startswith('*ЦХИ'):  # выбираем только реплики ребенка \n",
    "                line = re.sub('\"*\".*', '', line)\n",
    "                line = re.sub('[0-9_]', '', line)\n",
    "                textChild += line.lower()\n",
    "            elif line.startswith('*'):\n",
    "                line = re.sub('\"*\".*', '', line)\n",
    "                line = re.sub('[0-9_]', '', line)\n",
    "                textParents += line.lower()\n",
    "        \n",
    "with open('TosiaSays.txt', 'w+', encoding='utf-8') as f:\n",
    "    f.write(textChild)\n",
    "with open('TosiaHears.txt', 'w+', encoding='utf-8') as f:\n",
    "    f.write(textParents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WordsCounting(filepath):\n",
    "    with open(filepath, 'r+', encoding='utf-8') as f:\n",
    "        text = f.readlines()\n",
    "        # список из всех слов, которые говорит или слышит ребенок\n",
    "        words = []\n",
    "        for line in text:\n",
    "            for word in line.lower().translate(str.maketrans(dict.fromkeys(string.punctuation))).split():\n",
    "                words.append(word)\n",
    "\n",
    "    # список из словрей вида слово:часть речи\n",
    "    dict_words = [] \n",
    "    for word in words:\n",
    "        pos = morph.parse(word)[0].tag.POS\n",
    "        d = {}\n",
    "        d[word] = pos\n",
    "        dict_words.append(d)\n",
    "    \n",
    "    # список из частей речи всех слов -- для частеречного анализа\n",
    "    pos = []\n",
    "    for d in dict_words:\n",
    "        for values in d.values():\n",
    "            if values != None:\n",
    "                pos.append(values)\n",
    "    \n",
    "    # топ частей речи, которые слышит или говорит ребенок\n",
    "    top_pos = Counter(pos)\n",
    "    print('Распределение по частям речи ', top_pos)\n",
    "    \n",
    "    # топ-10 слов и топ-10 существительных, которые слышит или говорит ребенок\n",
    "    all_words = []\n",
    "    all_nouns = []\n",
    "    forbidden = ['цхи', 'ххх', 'мот', 'фат', 'æто',\n",
    "                 'лаугхинга', 'чико', 'нана', 'мотхер', 'бро',\n",
    "                 'мота', 'xxx', 'сис']\n",
    "    for d in dict_words:\n",
    "        for key, value in d.items():\n",
    "            key = morph.parse(key)[0].normal_form\n",
    "            if key not in forbidden:\n",
    "                all_words.append(key)\n",
    "            if value == 'NOUN' and key not in forbidden:\n",
    "                all_nouns.append(key)\n",
    "                \n",
    "    sw = stopwords.words('russian')\n",
    "    \n",
    "    filtered_words = [w for w in all_words if w not in sw]\n",
    "    filtered_nouns = [w for w in all_nouns if w not in sw]\n",
    "    \n",
    "    top_words = Counter(filtered_words)\n",
    "    top_words = dict(top_words)\n",
    "    top_words = {c: top_words[c] for c in top_words if top_words[c] > 2 and len(c) > 2}\n",
    "    top_words = (sorted(top_words.items(), key=lambda x: x[1], reverse=True))[:10]\n",
    "    \n",
    "    top_nouns = Counter(filtered_nouns)\n",
    "    top_nouns = dict(top_nouns)\n",
    "    top_nouns = {c: top_nouns[c] for c in top_nouns if top_nouns[c] > 2 and len(c) > 2}\n",
    "    top_nouns = (sorted(top_nouns.items(), key=lambda x: x[1], reverse=True))[:10]\n",
    "    \n",
    "    print('Топ-10 всех слов', top_words)\n",
    "    print('Топ-10 всех существительных', top_nouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Что Тося говорит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Распределение по частям речи  Counter({'NOUN': 2692, 'NPRO': 1328, 'VERB': 1270, 'PRCL': 1237, 'CONJ': 559, 'ADVB': 525, 'ADJF': 480, 'PRED': 464, 'INTJ': 345, 'PREP': 295, 'INFN': 213, 'NUMR': 75, 'ADJS': 58, 'GRND': 45, 'COMP': 27, 'PRTS': 7})\n",
      "Топ-10 всех слов [('xxx', 300), ('xочить', 102), ('няня', 100), ('ешчё', 88), ('ама', 83), ('смотреть', 77), ('видеть', 76), ('мочь', 62), ('большой', 62), ('варя', 54)]\n",
      "Топ-10 всех существительных [('няня', 100), ('ешчё', 88), ('ама', 83), ('варя', 54), ('тося', 52), ('мама', 36), ('стасик', 33), ('шчас', 26), ('метр', 25), ('папа', 24)]\n"
     ]
    }
   ],
   "source": [
    "WordsCounting('TosiaSays.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Что Тося слышит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Распределение по частям речи  Counter({'NOUN': 16326, 'VERB': 4508, 'CONJ': 3016, 'NPRO': 2884, 'PRCL': 2788, 'ADVB': 1943, 'PREP': 1725, 'ADJF': 1632, 'INFN': 906, 'INTJ': 662, 'PRED': 431, 'ADJS': 405, 'GRND': 225, 'NUMR': 168, 'COMP': 93, 'PRTS': 39, 'PRTF': 16})\n",
      "Топ-10 всех слов [('нанна', 567), ('тося', 458), ('сис', 302), ('давать', 301), ('смотреть', 163), ('ешчё', 161), ('xxx', 160), ('мочь', 139), ('сказать', 135), ('весь', 135)]\n",
      "Топ-10 всех существительных [('нанна', 567), ('тося', 458), ('ешчё', 161), ('тосй', 109), ('мама', 102), ('шчас', 78), ('тоня', 67), ('варя', 63), ('свет', 59), ('молодец', 54)]\n"
     ]
    }
   ],
   "source": [
    "WordsCounting('TosiaHears.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Яша"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Скачивание файлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = []\n",
    "for i in os.walk('childes_Yasha'):\n",
    "    folder.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводим список всех файлов и папок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = []\n",
    "for address, dirs, files in folder:\n",
    "    for file in files:\n",
    "        filenames.append(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводим список всех файлов, содержащих диалоги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10.txt', '11.txt', '12.txt', '13.06.2018.txt', '13.txt', '13_02_2018.txt', '14.txt', '15.txt', '16.txt', '18.txt', '19.txt', '20.txt', '21.cha', '22.cha', '22_02_2018.cha', '23.cha', '24.cha', '24_03_2018.cha', '25.cha', '26.cha', '27.01.2018.cha', '27.cha', '6_02_2018.txt', '7.txt', '8.txt']\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "new = []\n",
    "for filename in filenames:\n",
    "    if filename[0].isnumeric():\n",
    "        new.append(filename)\n",
    "print(new)\n",
    "print(len(new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []  # список готовых директорий к файлам с диалогами\n",
    "for filename in new:\n",
    "    directory = 'childes_Yasha/'\n",
    "    path = directory + filename\n",
    "    paths.append(path)\n",
    "    #print(path)\n",
    "\n",
    "#print(len(paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разделение реплик на то, что ребенок слышит, и то, что он говорит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "dict_words = []\n",
    "\n",
    "for filename in paths:\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        file = f.readlines()\n",
    "        textChild = ''\n",
    "        textParents = ''\n",
    "        for line in file:\n",
    "            line = translit(line, 'ru')\n",
    "            line = re.sub('йо', 'ё', line)\n",
    "            if line.startswith('*ЦХИ'):  # выбираем только реплики ребенка \n",
    "                line = re.sub('\"*\".*', '', line)\n",
    "                line = re.sub('[0-9_]', '', line)\n",
    "                textChild += line.lower()\n",
    "            elif line.startswith('*'):\n",
    "                line = re.sub('\"*\".*', '', line)\n",
    "                line = re.sub('[0-9_]', '', line)\n",
    "                textParents += line.lower()\n",
    "        \n",
    "with open('YashaSays.txt', 'w+', encoding='utf-8') as f:\n",
    "    f.write(textChild)\n",
    "with open('YashaHears.txt', 'w+', encoding='utf-8') as f:\n",
    "    f.write(textParents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Что Яша говорит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Распределение по частям речи  Counter({'NOUN': 233, 'PREP': 53, 'INTJ': 33, 'VERB': 24, 'ADVB': 16, 'PRCL': 7, 'ADJF': 6, 'PRED': 5, 'NUMR': 4, 'ADJS': 3, 'CONJ': 3, 'INFN': 3})\n",
      "Топ-10 всех слов [('ала', 18), ('картошка', 15), ('деу', 14), ('мемец', 12), ('мультик', 12), ('вилка', 10), ('дать', 10), ('тятёца', 9), ('пац', 7), ('алло', 7)]\n",
      "Топ-10 всех существительных [('ала', 18), ('картошка', 15), ('мемец', 12), ('мультик', 12), ('вилка', 10), ('тятёца', 9), ('яша', 5), ('татёца', 5), ('папа', 4), ('миша', 4)]\n"
     ]
    }
   ],
   "source": [
    "WordsCounting('YashaSays.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Что Яша слышит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Распределение по частям речи  Counter({'NOUN': 1286, 'CONJ': 472, 'VERB': 452, 'NPRO': 300, 'PRCL': 277, 'ADVB': 155, 'PREP': 127, 'ADJF': 81, 'INFN': 63, 'INTJ': 60, 'PRED': 38, 'ADJS': 17, 'COMP': 8, 'NUMR': 6, 'GRND': 4, 'PRTS': 2, 'PRTF': 1})\n",
      "Топ-10 всех слов [('яша', 109), ('написать', 37), ('говорить', 30), ('давать', 28), ('сказать', 24), ('спать', 24), ('ешчё', 20), ('пожалуйста', 19), ('картошка', 18), ('мусор', 17)]\n",
      "Топ-10 всех существительных [('яша', 109), ('ешчё', 20), ('картошка', 18), ('мусор', 17), ('стол', 16), ('пупок', 16), ('салат', 12), ('буква', 12), ('коляска', 11), ('крокодил', 11)]\n"
     ]
    }
   ],
   "source": [
    "WordsCounting('YashaHears.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
